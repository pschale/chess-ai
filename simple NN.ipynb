{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pschale/anaconda/envs/tf/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import chess_game as cg\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = tflearn.layers.core.input_data(shape=(None, 64, 8), name='board_input')\n",
    "aux = tflearn.layers.core.input_data(shape=(None, 7), name='aux_input')\n",
    "Y = tflearn.layers.core.input_data(shape=(None, 3), name='labels')\n",
    "\n",
    "board_input_reshaped = tf.reshape(board, [-1, 8, 8, 8])\n",
    "\n",
    "conv4 = tflearn.conv_2d(board_input_reshaped, 32, 4, activation='relu')\n",
    "\n",
    "\n",
    "conv2 = tflearn.conv_2d(board_input_reshaped, 32, 2, activation='relu')\n",
    "conv2_4 = tflearn.conv_2d(conv2, 64, 4, activation='relu')\n",
    "# note: this is how to get separate branches of a larger NN and then have them converge\n",
    "fc1 = tflearn.layers.core.fully_connected(tf.concat([conv4, conv2_4], 3), n_units=1000, activation='relu')\n",
    "\n",
    "fc2 = tflearn.layers.core.fully_connected(tf.concat([fc1, aux], 1), n_units=2000, activation='relu')\n",
    "\n",
    "net = tflearn.layers.core.fully_connected(fc2, n_units=3, activation='softmax')\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=net, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#net = tflearn.regression(net, optimizer='adam', metric=loss,\n",
    "#                         loss='categorical_crossentropy')\n",
    "#model = tflearn.DNN(net, tensorboard_verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('board_positions/board_positions_1.csv')\n",
    "a = a[~a.isnull().any(axis=1)]\n",
    "a = a[a['moves_in_game'] - a['move_num']<10]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['k', 'q', 'r', 'b', 'n', 'p', ' ', 'P', 'N', 'B', 'R', 'Q', 'K'])\n",
    "\n",
    "bcols = a.columns[:64]\n",
    "\n",
    "a[bcols] = le.transform(a[bcols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(data):\n",
    "    \n",
    "    d = data.sample(100)\n",
    "    train = d[d.columns[:71]]\n",
    "    board = train[train.columns[:64]]\n",
    "    aux = train[train.columns[64:]]\n",
    "    board_onehot = np.zeros((100, 64, 8))\n",
    "    board_onehot[:, :, 0] = board.isin([7, 8, 9, 10, 11, 12])\n",
    "    board_onehot[:, :, 1] = board.isin([0, 1, 2, 3, 4, 5])\n",
    "    board_onehot[:, :, 2] = board.isin([0, 12])\n",
    "    board_onehot[:, :, 3] = board.isin([1, 11])\n",
    "    board_onehot[:, :, 4] = board.isin([2, 10])\n",
    "    board_onehot[:, :, 5] = board.isin([3, 9])\n",
    "    board_onehot[:, :, 6] = board.isin([4, 8])\n",
    "    board_onehot[:, :, 7] = board.isin([5, 7])\n",
    "    labels = np.zeros((100,3))\n",
    "    labels[d['winner']==-1, 0] = 1\n",
    "    labels[d['winner']==0, 1] = 1\n",
    "    labels[d['winner']==1, 2] = 1\n",
    "    \n",
    "    return board_onehot, aux, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 Step: 000 Loss: 1.1061362\n",
      "Epoch: 001 Step: 020 Loss: 1.0445443\n",
      "Epoch: 001 Step: 040 Loss: 1.0402567\n",
      "Epoch: 001 Step: 060 Loss: 1.0193391\n",
      "Epoch: 001 Step: 080 Loss: 0.99248093\n",
      "Epoch: 001 Step: 100 Loss: 0.96708727\n",
      "Epoch: 001 Step: 120 Loss: 0.9682187\n",
      "Epoch: 001 Step: 140 Loss: 0.9495423\n",
      "Epoch: 001 Step: 160 Loss: 0.96677107\n",
      "Epoch: 001 Step: 180 Loss: 0.88641965\n",
      "Epoch: 002 Step: 000 Loss: 0.97250783\n",
      "Epoch: 002 Step: 020 Loss: 0.91933334\n",
      "Epoch: 002 Step: 040 Loss: 0.9124889\n",
      "Epoch: 002 Step: 060 Loss: 0.9255668\n",
      "Epoch: 002 Step: 080 Loss: 0.9032878\n",
      "Epoch: 002 Step: 100 Loss: 0.89139205\n",
      "Epoch: 002 Step: 120 Loss: 0.890964\n",
      "Epoch: 002 Step: 140 Loss: 0.95472413\n",
      "Epoch: 002 Step: 160 Loss: 0.95608824\n",
      "Epoch: 002 Step: 180 Loss: 0.943003\n",
      "Epoch: 003 Step: 000 Loss: 0.9093886\n",
      "Epoch: 003 Step: 020 Loss: 0.9260199\n",
      "Epoch: 003 Step: 040 Loss: 0.90726995\n",
      "Epoch: 003 Step: 060 Loss: 0.8952315\n",
      "Epoch: 003 Step: 080 Loss: 0.92401034\n",
      "Epoch: 003 Step: 100 Loss: 0.8851005\n",
      "Epoch: 003 Step: 120 Loss: 0.90965414\n",
      "Epoch: 003 Step: 140 Loss: 0.89697045\n",
      "Epoch: 003 Step: 160 Loss: 0.8920633\n",
      "Epoch: 003 Step: 180 Loss: 0.8825623\n",
      "Epoch: 004 Step: 000 Loss: 0.92180955\n",
      "Epoch: 004 Step: 020 Loss: 0.8395258\n",
      "Epoch: 004 Step: 040 Loss: 0.90220594\n",
      "Epoch: 004 Step: 060 Loss: 0.87954986\n",
      "Epoch: 004 Step: 080 Loss: 0.9116439\n",
      "Epoch: 004 Step: 100 Loss: 0.95457196\n",
      "Epoch: 004 Step: 120 Loss: 0.8819531\n",
      "Epoch: 004 Step: 140 Loss: 0.83759254\n",
      "Epoch: 004 Step: 160 Loss: 0.8838549\n",
      "Epoch: 004 Step: 180 Loss: 0.8126537\n",
      "Epoch: 005 Step: 000 Loss: 0.88475645\n",
      "Epoch: 005 Step: 020 Loss: 0.78928953\n",
      "Epoch: 005 Step: 040 Loss: 0.933693\n",
      "Epoch: 005 Step: 060 Loss: 0.8917835\n",
      "Epoch: 005 Step: 080 Loss: 0.88993454\n",
      "Epoch: 005 Step: 100 Loss: 0.8775274\n",
      "Epoch: 005 Step: 120 Loss: 0.85688585\n",
      "Epoch: 005 Step: 140 Loss: 0.93497103\n",
      "Epoch: 005 Step: 160 Loss: 0.8842525\n",
      "Epoch: 005 Step: 180 Loss: 0.94237536\n",
      "Epoch: 006 Step: 000 Loss: 0.87993395\n",
      "Epoch: 006 Step: 020 Loss: 0.8982677\n",
      "Epoch: 006 Step: 040 Loss: 0.89231735\n",
      "Epoch: 006 Step: 060 Loss: 0.8689457\n",
      "Epoch: 006 Step: 080 Loss: 0.89777815\n",
      "Epoch: 006 Step: 100 Loss: 0.8376255\n",
      "Epoch: 006 Step: 120 Loss: 0.8838562\n",
      "Epoch: 006 Step: 140 Loss: 0.92118835\n",
      "Epoch: 006 Step: 160 Loss: 0.817799\n",
      "Epoch: 006 Step: 180 Loss: 0.8661527\n",
      "Epoch: 007 Step: 000 Loss: 0.9401571\n",
      "Epoch: 007 Step: 020 Loss: 0.8917568\n",
      "Epoch: 007 Step: 040 Loss: 0.8389994\n",
      "Epoch: 007 Step: 060 Loss: 0.8721524\n",
      "Epoch: 007 Step: 080 Loss: 0.8549075\n",
      "Epoch: 007 Step: 100 Loss: 0.8865826\n",
      "Epoch: 007 Step: 120 Loss: 0.86088586\n",
      "Epoch: 007 Step: 140 Loss: 0.92363137\n",
      "Epoch: 007 Step: 160 Loss: 0.81014794\n",
      "Epoch: 007 Step: 180 Loss: 0.8238588\n",
      "Epoch: 008 Step: 000 Loss: 0.90017885\n",
      "Epoch: 008 Step: 020 Loss: 0.8662252\n",
      "Epoch: 008 Step: 040 Loss: 0.88827795\n",
      "Epoch: 008 Step: 060 Loss: 0.88446075\n",
      "Epoch: 008 Step: 080 Loss: 0.90946954\n",
      "Epoch: 008 Step: 100 Loss: 0.850987\n",
      "Epoch: 008 Step: 120 Loss: 0.87362444\n",
      "Epoch: 008 Step: 140 Loss: 0.82593393\n",
      "Epoch: 008 Step: 160 Loss: 0.8873936\n",
      "Epoch: 008 Step: 180 Loss: 0.8538304\n",
      "Epoch: 009 Step: 000 Loss: 0.83661765\n",
      "Epoch: 009 Step: 020 Loss: 0.81986123\n",
      "Epoch: 009 Step: 040 Loss: 0.885128\n",
      "Epoch: 009 Step: 060 Loss: 0.8277868\n",
      "Epoch: 009 Step: 080 Loss: 0.8429672\n",
      "Epoch: 009 Step: 100 Loss: 0.8996887\n",
      "Epoch: 009 Step: 120 Loss: 0.84336317\n",
      "Epoch: 009 Step: 140 Loss: 0.8713975\n",
      "Epoch: 009 Step: 160 Loss: 0.80749863\n",
      "Epoch: 009 Step: 180 Loss: 0.86798155\n",
      "Epoch: 010 Step: 000 Loss: 0.83548623\n",
      "Epoch: 010 Step: 020 Loss: 0.870385\n",
      "Epoch: 010 Step: 040 Loss: 0.8794338\n",
      "Epoch: 010 Step: 060 Loss: 0.8081071\n",
      "Epoch: 010 Step: 080 Loss: 0.8294371\n",
      "Epoch: 010 Step: 100 Loss: 0.87341666\n",
      "Epoch: 010 Step: 120 Loss: 0.7478848\n",
      "Epoch: 010 Step: 140 Loss: 0.8256997\n",
      "Epoch: 010 Step: 160 Loss: 0.88275146\n",
      "Epoch: 010 Step: 180 Loss: 0.81959784\n",
      "Epoch: 011 Step: 000 Loss: 0.85006404\n",
      "Epoch: 011 Step: 020 Loss: 0.8579592\n",
      "Epoch: 011 Step: 040 Loss: 0.82328296\n",
      "Epoch: 011 Step: 060 Loss: 0.8113534\n",
      "Epoch: 011 Step: 080 Loss: 0.83178955\n",
      "Epoch: 011 Step: 100 Loss: 0.9032986\n",
      "Epoch: 011 Step: 120 Loss: 0.86342615\n",
      "Epoch: 011 Step: 140 Loss: 0.90295744\n",
      "Epoch: 011 Step: 160 Loss: 0.8766927\n",
      "Epoch: 011 Step: 180 Loss: 0.8056952\n",
      "Epoch: 012 Step: 000 Loss: 0.8114714\n",
      "Epoch: 012 Step: 020 Loss: 0.73601836\n",
      "Epoch: 012 Step: 040 Loss: 0.80547243\n",
      "Epoch: 012 Step: 060 Loss: 0.7894932\n",
      "Epoch: 012 Step: 080 Loss: 0.808686\n",
      "Epoch: 012 Step: 100 Loss: 0.9204474\n",
      "Epoch: 012 Step: 120 Loss: 0.84680307\n",
      "Epoch: 012 Step: 140 Loss: 0.8740305\n",
      "Epoch: 012 Step: 160 Loss: 0.8378553\n",
      "Epoch: 012 Step: 180 Loss: 0.8198547\n",
      "Epoch: 013 Step: 000 Loss: 0.8856385\n",
      "Epoch: 013 Step: 020 Loss: 0.84295225\n",
      "Epoch: 013 Step: 040 Loss: 0.80656034\n",
      "Epoch: 013 Step: 060 Loss: 0.7925285\n",
      "Epoch: 013 Step: 080 Loss: 0.85312635\n",
      "Epoch: 013 Step: 100 Loss: 0.85912627\n",
      "Epoch: 013 Step: 120 Loss: 0.9228366\n",
      "Epoch: 013 Step: 140 Loss: 0.8466694\n",
      "Epoch: 013 Step: 160 Loss: 0.803842\n",
      "Epoch: 013 Step: 180 Loss: 0.7962557\n",
      "Epoch: 014 Step: 000 Loss: 0.8438296\n",
      "Epoch: 014 Step: 020 Loss: 0.7872852\n",
      "Epoch: 014 Step: 040 Loss: 0.8709779\n",
      "Epoch: 014 Step: 060 Loss: 0.831444\n",
      "Epoch: 014 Step: 080 Loss: 0.8675638\n",
      "Epoch: 014 Step: 100 Loss: 0.8078371\n",
      "Epoch: 014 Step: 120 Loss: 0.8392942\n",
      "Epoch: 014 Step: 140 Loss: 0.80002874\n",
      "Epoch: 014 Step: 160 Loss: 0.8561881\n",
      "Epoch: 014 Step: 180 Loss: 0.89192903\n",
      "Epoch: 015 Step: 000 Loss: 0.8097147\n",
      "Epoch: 015 Step: 020 Loss: 0.77610296\n",
      "Epoch: 015 Step: 040 Loss: 0.8285043\n",
      "Epoch: 015 Step: 060 Loss: 0.872166\n",
      "Epoch: 015 Step: 080 Loss: 0.812743\n",
      "Epoch: 015 Step: 100 Loss: 0.8236306\n",
      "Epoch: 015 Step: 120 Loss: 0.82845426\n",
      "Epoch: 015 Step: 140 Loss: 0.8771442\n",
      "Epoch: 015 Step: 160 Loss: 0.8719127\n",
      "Epoch: 015 Step: 180 Loss: 0.78852034\n",
      "Epoch: 016 Step: 000 Loss: 0.7979251\n",
      "Epoch: 016 Step: 020 Loss: 0.79403573\n",
      "Epoch: 016 Step: 040 Loss: 0.8351604\n",
      "Epoch: 016 Step: 060 Loss: 0.82802755\n",
      "Epoch: 016 Step: 080 Loss: 0.8192582\n",
      "Epoch: 016 Step: 100 Loss: 0.81956846\n",
      "Epoch: 016 Step: 120 Loss: 0.82277304\n",
      "Epoch: 016 Step: 140 Loss: 0.8774794\n",
      "Epoch: 016 Step: 160 Loss: 0.801062\n",
      "Epoch: 016 Step: 180 Loss: 0.7817015\n",
      "Epoch: 017 Step: 000 Loss: 0.84754837\n",
      "Epoch: 017 Step: 020 Loss: 0.83219236\n",
      "Epoch: 017 Step: 040 Loss: 0.812355\n",
      "Epoch: 017 Step: 060 Loss: 0.8272997\n",
      "Epoch: 017 Step: 080 Loss: 0.8067346\n",
      "Epoch: 017 Step: 100 Loss: 0.8324604\n",
      "Epoch: 017 Step: 120 Loss: 0.82393163\n",
      "Epoch: 017 Step: 140 Loss: 0.8461565\n",
      "Epoch: 017 Step: 160 Loss: 0.77067983\n",
      "Epoch: 017 Step: 180 Loss: 0.80751586\n",
      "Epoch: 018 Step: 000 Loss: 0.8289644\n",
      "Epoch: 018 Step: 020 Loss: 0.816024\n",
      "Epoch: 018 Step: 040 Loss: 0.80140686\n",
      "Epoch: 018 Step: 060 Loss: 0.7894742\n",
      "Epoch: 018 Step: 080 Loss: 0.7623177\n",
      "Epoch: 018 Step: 100 Loss: 0.8132697\n",
      "Epoch: 018 Step: 120 Loss: 0.78538877\n",
      "Epoch: 018 Step: 140 Loss: 0.79396266\n",
      "Epoch: 018 Step: 160 Loss: 0.8225368\n",
      "Epoch: 018 Step: 180 Loss: 0.8190732\n",
      "Epoch: 019 Step: 000 Loss: 0.81038404\n",
      "Epoch: 019 Step: 020 Loss: 0.8410863\n",
      "Epoch: 019 Step: 040 Loss: 0.80157745\n",
      "Epoch: 019 Step: 060 Loss: 0.8485228\n",
      "Epoch: 019 Step: 080 Loss: 0.81745857\n",
      "Epoch: 019 Step: 100 Loss: 0.78070265\n",
      "Epoch: 019 Step: 120 Loss: 0.8309515\n",
      "Epoch: 019 Step: 140 Loss: 0.8316699\n",
      "Epoch: 019 Step: 160 Loss: 0.85005724\n",
      "Epoch: 019 Step: 180 Loss: 0.82051384\n",
      "Epoch: 020 Step: 000 Loss: 0.85732704\n",
      "Epoch: 020 Step: 020 Loss: 0.8674234\n",
      "Epoch: 020 Step: 040 Loss: 0.80927575\n",
      "Epoch: 020 Step: 060 Loss: 0.831982\n",
      "Epoch: 020 Step: 080 Loss: 0.77902013\n",
      "Epoch: 020 Step: 100 Loss: 0.8449042\n",
      "Epoch: 020 Step: 120 Loss: 0.75228447\n",
      "Epoch: 020 Step: 140 Loss: 0.7692308\n",
      "Epoch: 020 Step: 160 Loss: 0.78463227\n",
      "Epoch: 020 Step: 180 Loss: 0.76027715\n",
      "Epoch: 021 Step: 000 Loss: 0.83973944\n",
      "Epoch: 021 Step: 020 Loss: 0.8122998\n",
      "Epoch: 021 Step: 040 Loss: 0.829517\n",
      "Epoch: 021 Step: 060 Loss: 0.75082666\n",
      "Epoch: 021 Step: 080 Loss: 0.8100506\n",
      "Epoch: 021 Step: 100 Loss: 0.8259898\n",
      "Epoch: 021 Step: 120 Loss: 0.8400872\n",
      "Epoch: 021 Step: 140 Loss: 0.7599444\n",
      "Epoch: 021 Step: 160 Loss: 0.8707979\n",
      "Epoch: 021 Step: 180 Loss: 0.7275904\n",
      "Epoch: 022 Step: 000 Loss: 0.8635516\n",
      "Epoch: 022 Step: 020 Loss: 0.7978044\n",
      "Epoch: 022 Step: 040 Loss: 0.7650847\n",
      "Epoch: 022 Step: 060 Loss: 0.7868054\n",
      "Epoch: 022 Step: 080 Loss: 0.806623\n",
      "Epoch: 022 Step: 100 Loss: 0.8177858\n",
      "Epoch: 022 Step: 120 Loss: 0.827762\n",
      "Epoch: 022 Step: 140 Loss: 0.8232713\n",
      "Epoch: 022 Step: 160 Loss: 0.78108805\n",
      "Epoch: 022 Step: 180 Loss: 0.85616165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023 Step: 000 Loss: 0.782693\n",
      "Epoch: 023 Step: 020 Loss: 0.8113545\n",
      "Epoch: 023 Step: 040 Loss: 0.77444476\n",
      "Epoch: 023 Step: 060 Loss: 0.7981622\n",
      "Epoch: 023 Step: 080 Loss: 0.7650945\n",
      "Epoch: 023 Step: 100 Loss: 0.81216574\n",
      "Epoch: 023 Step: 120 Loss: 0.79549235\n",
      "Epoch: 023 Step: 140 Loss: 0.7883401\n",
      "Epoch: 023 Step: 160 Loss: 0.81689036\n",
      "Epoch: 023 Step: 180 Loss: 0.83788145\n",
      "Epoch: 024 Step: 000 Loss: 0.80846345\n",
      "Epoch: 024 Step: 020 Loss: 0.7817747\n",
      "Epoch: 024 Step: 040 Loss: 0.7549716\n",
      "Epoch: 024 Step: 060 Loss: 0.76159173\n",
      "Epoch: 024 Step: 080 Loss: 0.8310031\n",
      "Epoch: 024 Step: 100 Loss: 0.79243195\n",
      "Epoch: 024 Step: 120 Loss: 0.78161454\n",
      "Epoch: 024 Step: 140 Loss: 0.8176422\n",
      "Epoch: 024 Step: 160 Loss: 0.79923517\n",
      "Epoch: 024 Step: 180 Loss: 0.7612796\n",
      "Epoch: 025 Step: 000 Loss: 0.81551325\n",
      "Epoch: 025 Step: 020 Loss: 0.8452757\n",
      "Epoch: 025 Step: 040 Loss: 0.81320554\n",
      "Epoch: 025 Step: 060 Loss: 0.8537542\n",
      "Epoch: 025 Step: 080 Loss: 0.76204133\n",
      "Epoch: 025 Step: 100 Loss: 0.7839742\n",
      "Epoch: 025 Step: 120 Loss: 0.8447623\n",
      "Epoch: 025 Step: 140 Loss: 0.8718814\n",
      "Epoch: 025 Step: 160 Loss: 0.80443275\n",
      "Epoch: 025 Step: 180 Loss: 0.7999232\n",
      "Epoch: 026 Step: 000 Loss: 0.85551786\n",
      "Epoch: 026 Step: 020 Loss: 0.76219124\n",
      "Epoch: 026 Step: 040 Loss: 0.76929015\n",
      "Epoch: 026 Step: 060 Loss: 0.74884087\n",
      "Epoch: 026 Step: 080 Loss: 0.76295006\n",
      "Epoch: 026 Step: 100 Loss: 0.75483596\n",
      "Epoch: 026 Step: 120 Loss: 0.8008763\n",
      "Epoch: 026 Step: 140 Loss: 0.80318564\n",
      "Epoch: 026 Step: 160 Loss: 0.74522763\n",
      "Epoch: 026 Step: 180 Loss: 0.7694533\n",
      "Epoch: 027 Step: 000 Loss: 0.8299101\n",
      "Epoch: 027 Step: 020 Loss: 0.79387647\n",
      "Epoch: 027 Step: 040 Loss: 0.80607146\n",
      "Epoch: 027 Step: 060 Loss: 0.7308744\n",
      "Epoch: 027 Step: 080 Loss: 0.8188223\n",
      "Epoch: 027 Step: 100 Loss: 0.7415251\n",
      "Epoch: 027 Step: 120 Loss: 0.857396\n",
      "Epoch: 027 Step: 140 Loss: 0.7972579\n",
      "Epoch: 027 Step: 160 Loss: 0.7440701\n",
      "Epoch: 027 Step: 180 Loss: 0.79895455\n",
      "Epoch: 028 Step: 000 Loss: 0.77642596\n",
      "Epoch: 028 Step: 020 Loss: 0.8005214\n",
      "Epoch: 028 Step: 040 Loss: 0.75189394\n",
      "Epoch: 028 Step: 060 Loss: 0.8439402\n",
      "Epoch: 028 Step: 080 Loss: 0.77588916\n",
      "Epoch: 028 Step: 100 Loss: 0.81001574\n",
      "Epoch: 028 Step: 120 Loss: 0.80650437\n",
      "Epoch: 028 Step: 140 Loss: 0.84960616\n",
      "Epoch: 028 Step: 160 Loss: 0.7413121\n",
      "Epoch: 028 Step: 180 Loss: 0.73801446\n",
      "Epoch: 029 Step: 000 Loss: 0.7741153\n",
      "Epoch: 029 Step: 020 Loss: 0.76478976\n",
      "Epoch: 029 Step: 040 Loss: 0.7784404\n",
      "Epoch: 029 Step: 060 Loss: 0.79957604\n",
      "Epoch: 029 Step: 080 Loss: 0.78542274\n",
      "Epoch: 029 Step: 100 Loss: 0.753972\n",
      "Epoch: 029 Step: 120 Loss: 0.81595474\n",
      "Epoch: 029 Step: 140 Loss: 0.75387007\n",
      "Epoch: 029 Step: 160 Loss: 0.7283804\n",
      "Epoch: 029 Step: 180 Loss: 0.80485404\n",
      "Epoch: 030 Step: 000 Loss: 0.75318885\n",
      "Epoch: 030 Step: 020 Loss: 0.8118449\n",
      "Epoch: 030 Step: 040 Loss: 0.82614404\n",
      "Epoch: 030 Step: 060 Loss: 0.7500932\n",
      "Epoch: 030 Step: 080 Loss: 0.7538899\n",
      "Epoch: 030 Step: 100 Loss: 0.77131987\n",
      "Epoch: 030 Step: 120 Loss: 0.81587356\n",
      "Epoch: 030 Step: 140 Loss: 0.8430701\n",
      "Epoch: 030 Step: 160 Loss: 0.7502603\n",
      "Epoch: 030 Step: 180 Loss: 0.7519221\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(30):  # 2 epochs\n",
    "    for i in range(200):\n",
    "        batch_board, batch_aux, batch_ys = get_training_data(a)\n",
    "        sess.run(optimizer, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})\n",
    "        cost = sess.run(loss, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(\"Epoch:\", '%03d' % (epoch + 1), \"Step:\", '%03d' % i,\n",
    "                  \"Loss:\", str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.42465615e-01, 5.99367340e-05, 2.57474482e-01],\n",
       "       [9.96362984e-01, 2.49989214e-04, 3.38701997e-03],\n",
       "       [9.96493518e-01, 4.20306111e-04, 3.08620953e-03],\n",
       "       [9.77828085e-01, 2.67387426e-04, 2.19045598e-02],\n",
       "       [1.20456088e-02, 9.53483759e-05, 9.87859070e-01],\n",
       "       [9.79022920e-01, 2.09347270e-02, 4.23674173e-05],\n",
       "       [8.25399533e-03, 8.42824054e-04, 9.90903199e-01],\n",
       "       [2.09046621e-02, 1.45416660e-03, 9.77641165e-01],\n",
       "       [9.73291516e-01, 2.85349926e-03, 2.38549858e-02],\n",
       "       [7.21077800e-01, 2.34364681e-02, 2.55485833e-01],\n",
       "       [3.44967358e-02, 1.31923720e-01, 8.33579600e-01],\n",
       "       [9.99983907e-01, 8.04493720e-06, 8.10684378e-06],\n",
       "       [2.05605775e-01, 1.11951180e-04, 7.94282258e-01],\n",
       "       [1.77569002e-01, 6.32049807e-04, 8.21798921e-01],\n",
       "       [9.96743023e-01, 6.66271371e-05, 3.19040334e-03],\n",
       "       [3.89866112e-03, 8.17905857e-06, 9.96093214e-01],\n",
       "       [3.38504054e-02, 3.34322394e-05, 9.66116190e-01],\n",
       "       [3.50823030e-02, 2.74794846e-04, 9.64642882e-01],\n",
       "       [9.82223272e-01, 5.20584313e-03, 1.25708915e-02],\n",
       "       [1.37568310e-01, 7.19180171e-05, 8.62359762e-01],\n",
       "       [1.61083112e-03, 1.76873928e-05, 9.98371542e-01],\n",
       "       [1.93153918e-01, 9.73092174e-05, 8.06748748e-01],\n",
       "       [9.87033129e-01, 8.45230461e-05, 1.28823463e-02],\n",
       "       [9.02596116e-01, 1.93874515e-03, 9.54651833e-02],\n",
       "       [6.14079118e-01, 1.82323754e-04, 3.85738552e-01],\n",
       "       [8.23781788e-01, 1.11393270e-03, 1.75104231e-01],\n",
       "       [1.85855990e-03, 1.83016964e-05, 9.98123109e-01],\n",
       "       [1.72025873e-03, 3.56111355e-04, 9.97923613e-01],\n",
       "       [2.89538085e-01, 8.12495768e-04, 7.09649384e-01],\n",
       "       [1.24239042e-01, 7.57435918e-01, 1.18325047e-01],\n",
       "       [5.27144317e-03, 2.51380028e-04, 9.94477212e-01],\n",
       "       [3.54941760e-04, 5.43518644e-03, 9.94209886e-01],\n",
       "       [6.20964915e-02, 7.71463662e-02, 8.60757172e-01],\n",
       "       [9.98833597e-01, 1.75877522e-05, 1.14875438e-03],\n",
       "       [3.80343525e-03, 3.85732747e-05, 9.96158063e-01],\n",
       "       [9.17559028e-01, 3.56014185e-02, 4.68395837e-02],\n",
       "       [9.57390070e-01, 4.37603972e-04, 4.21723016e-02],\n",
       "       [1.34525972e-03, 2.45139690e-05, 9.98630285e-01],\n",
       "       [5.60748518e-01, 2.42218724e-03, 4.36829269e-01],\n",
       "       [1.13473658e-03, 1.79211402e-05, 9.98847365e-01],\n",
       "       [4.51005669e-03, 2.48996890e-04, 9.95240927e-01],\n",
       "       [6.60818160e-01, 1.06349087e-03, 3.38118434e-01],\n",
       "       [5.14349103e-01, 1.22611038e-03, 4.84424740e-01],\n",
       "       [1.78155780e-01, 1.19192280e-01, 7.02651918e-01],\n",
       "       [5.41046679e-01, 1.86321733e-04, 4.58767027e-01],\n",
       "       [9.98125970e-01, 1.86879840e-03, 5.22798518e-06],\n",
       "       [5.43064401e-02, 5.59199415e-03, 9.40101564e-01],\n",
       "       [8.40814573e-06, 5.60718445e-06, 9.99985933e-01],\n",
       "       [9.30167735e-01, 7.93892145e-03, 6.18933551e-02],\n",
       "       [3.18117514e-02, 7.30588290e-05, 9.68115211e-01],\n",
       "       [2.68564880e-01, 9.12614341e-05, 7.31343865e-01],\n",
       "       [7.81372547e-01, 1.06454603e-02, 2.07981959e-01],\n",
       "       [3.28832179e-01, 6.30400121e-01, 4.07676920e-02],\n",
       "       [8.08147609e-01, 1.79123342e-01, 1.27290506e-02],\n",
       "       [9.99566138e-01, 5.94636094e-06, 4.27867199e-04],\n",
       "       [1.91840036e-06, 8.63794594e-06, 9.99989390e-01],\n",
       "       [9.94168758e-01, 2.71802535e-03, 3.11327563e-03],\n",
       "       [9.93081391e-01, 2.58448278e-03, 4.33412567e-03],\n",
       "       [5.62251210e-01, 9.01685125e-05, 4.37658578e-01],\n",
       "       [9.94478464e-01, 1.93991553e-04, 5.32756373e-03],\n",
       "       [9.59858239e-01, 1.28193144e-02, 2.73225252e-02],\n",
       "       [9.07320499e-01, 4.01071981e-02, 5.25722727e-02],\n",
       "       [9.72796500e-01, 1.49893785e-05, 2.71885563e-02],\n",
       "       [4.51131850e-01, 5.97113632e-02, 4.89156753e-01],\n",
       "       [1.44566715e-01, 2.09267586e-04, 8.55224073e-01],\n",
       "       [3.40386643e-03, 3.62748541e-02, 9.60321248e-01],\n",
       "       [9.93561864e-01, 4.13257294e-05, 6.39681611e-03],\n",
       "       [3.39273224e-03, 3.28864008e-02, 9.63720858e-01],\n",
       "       [5.18929958e-01, 1.99221657e-03, 4.79077816e-01],\n",
       "       [4.31433797e-01, 1.93115033e-03, 5.66635072e-01],\n",
       "       [3.30222305e-04, 4.27035091e-04, 9.99242783e-01],\n",
       "       [8.17748070e-01, 9.91749985e-05, 1.82152748e-01],\n",
       "       [7.97532260e-01, 3.36113176e-03, 1.99106589e-01],\n",
       "       [2.35467795e-02, 1.59728597e-03, 9.74855959e-01],\n",
       "       [9.97984052e-01, 1.07103284e-03, 9.44860512e-04],\n",
       "       [1.39815509e-02, 1.80758434e-05, 9.86000359e-01],\n",
       "       [9.49649692e-01, 1.08448882e-03, 4.92657423e-02],\n",
       "       [9.00767267e-01, 5.66025497e-04, 9.86667424e-02],\n",
       "       [9.62876618e-01, 2.03217715e-02, 1.68015566e-02],\n",
       "       [2.09072357e-04, 4.00811294e-03, 9.95782852e-01],\n",
       "       [1.91840591e-05, 8.92960088e-05, 9.99891520e-01],\n",
       "       [6.75145984e-01, 1.19389256e-03, 3.23660135e-01],\n",
       "       [8.13360810e-02, 4.67785187e-02, 8.71885359e-01],\n",
       "       [1.90154031e-01, 1.74699491e-03, 8.08098972e-01],\n",
       "       [9.98445570e-01, 9.86603438e-04, 5.67889656e-04],\n",
       "       [1.04323104e-02, 4.32869745e-03, 9.85239029e-01],\n",
       "       [9.99295235e-01, 4.87032201e-04, 2.17751338e-04],\n",
       "       [8.17785156e-04, 3.04477107e-05, 9.99151707e-01],\n",
       "       [1.09534077e-02, 3.15664111e-05, 9.89015043e-01],\n",
       "       [4.44643199e-02, 3.02503631e-03, 9.52510655e-01],\n",
       "       [6.87928081e-01, 1.79612394e-02, 2.94110686e-01],\n",
       "       [4.27285908e-03, 5.09659731e-05, 9.95676219e-01],\n",
       "       [3.79270166e-02, 1.21805798e-02, 9.49892402e-01],\n",
       "       [9.02673483e-01, 4.68772538e-02, 5.04491664e-02],\n",
       "       [9.99710381e-01, 2.90813409e-06, 2.86680704e-04],\n",
       "       [8.59511495e-01, 1.52763922e-03, 1.38960883e-01],\n",
       "       [2.88329776e-02, 3.30497482e-04, 9.70836520e-01],\n",
       "       [1.67432718e-03, 1.74377169e-02, 9.80888009e-01],\n",
       "       [2.26485431e-01, 1.23812044e-02, 7.61133373e-01],\n",
       "       [9.98824894e-01, 3.53855194e-06, 1.17150636e-03]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_board, batch_aux, batch_ys = get_training_data(a)\n",
    "sess.run(net, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/pschale/pythonstuff/chess_ai_project/test_saved_CNN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, '/Users/pschale/pythonstuff/chess_ai_project/test_saved_CNN')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "WARNING:tensorflow:Error encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n",
      "INFO:tensorflow:SavedModel written to: b'/Users/pschale/pythonstuff/chess_ai_project/simple_saved/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.simple_save(sess, \n",
    "                            '/Users/pschale/pythonstuff/chess_ai_project/simple_saved',\n",
    "                          inputs={\"board\":board, \"aux\":aux},\n",
    "                          outputs={\"net\": net})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = cg.game_board()\n",
    "next_positions = b.find_all_next_board_positions('W')\n",
    "next_positions_ar = np.array([ele.to_csv_format() for ele in next_positions])\n",
    "next_positions_ar[:, :64] = le.transform(next_positions_ar[:, :64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_positions = b.find_all_next_board_positions('W')\n",
    "next_positions_ar = np.array([ele.to_csv_format() for ele in next_positions])\n",
    "next_positions_ar[:, :64] = le.transform(next_positions_ar[:, :64])\n",
    "\n",
    "next_scores = sess.run(net, feed_dict={X:next_positions_ar})\n",
    "b = next_positions[np.argmax(next_scores[:,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.move('Qxe5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('board_positions/board_positions_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a[a['moves_in_game'] - a['move_num']<10][a.columns[:71]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('board_positions/board_positions_1.csv')\n",
    "a = a[~a.isnull().any(axis=1)]\n",
    "a = a[a['moves_in_game'] - a['move_num']<10]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['k', 'q', 'r', 'b', 'n', 'p', ' ', 'P', 'N', 'B', 'R', 'Q', 'K'])\n",
    "\n",
    "bcols = a.columns[:64]\n",
    "\n",
    "a[bcols] = le.transform(a[bcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = a.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.as_matrix()[:, :64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train = c[c.columns[:71]]\n",
    "train_onehot = np.zeros((100, 71, 8))\n",
    "train_onehot[:, :, 0] = train.isin([7, 8, 9, 10, 11, 12])\n",
    "train_onehot[:, :, 1] = train.isin([0, 1, 2, 3, 4, 5])\n",
    "train_onehot[:, :, 2] = train.isin([0, 12])\n",
    "train_onehot[:, :, 3] = train.isin([1, 11])\n",
    "train_onehot[:, :, 4] = train.isin([2, 10])\n",
    "train_onehot[:, :, 5] = train.isin([3, 9])\n",
    "train_onehot[:, :, 6] = train.isin([4, 8])\n",
    "train_onehot[:, :, 7] = train.isin([5, 7])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
