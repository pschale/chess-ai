{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pschale/anaconda/envs/tf/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import chess_game as cg\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup for NN\n",
    "#if loading saved NN, must setup network same as before\n",
    "#current method of loading save only loads the values of the variables; everything has to be set up before that\n",
    "\n",
    "board = tflearn.layers.core.input_data(shape=(None, 64, 8), name='board_input')\n",
    "aux = tflearn.layers.core.input_data(shape=(None, 7), name='aux_input')\n",
    "Y = tflearn.layers.core.input_data(shape=(None, 3), name='labels')\n",
    "\n",
    "\n",
    "board_input_reshaped = tf.reshape(board, [-1, 8, 8, 8])\n",
    "\n",
    "conv4 = tflearn.conv_2d(board_input_reshaped, 64, [4,4], activation='relu')\n",
    "conv4 = tflearn.conv_2d(conv4, 128, [4,4], activation='relu')\n",
    "\n",
    "conv3 = tflearn.conv_2d(board_input_reshaped, 64, [3,3], activation='relu')\n",
    "conv3 = tflearn.conv_2d(board_input_reshaped, 128, [4,4], activation='relu')\n",
    "\n",
    "conv2 = tflearn.conv_2d(board_input_reshaped, 64, [2,2], activation='relu')\n",
    "conv2_4 = tflearn.conv_2d(conv2, 128, [4,4], activation='relu')\n",
    "\n",
    "ranks = tflearn.conv_2d(board_input_reshaped, 128, [1,8], activation='relu')\n",
    "files = tflearn.conv_2d(board_input_reshaped, 128, [8,1], activation='relu')\n",
    "\n",
    "\n",
    "# note: this is how to get separate branches of a larger NN and then have them converge\n",
    "fc1 = tflearn.layers.core.fully_connected(tf.concat([conv4, conv3, conv2_4, ranks, files], 3), n_units=5000, activation='relu')\n",
    "\n",
    "fc2 = tflearn.layers.core.fully_connected(tf.concat([fc1, aux], 1), n_units=2000, activation='relu')\n",
    "\n",
    "fc3 = tflearn.layers.core.fully_connected(fc2, n_units=500, activation='relu')\n",
    "\n",
    "net = tflearn.layers.core.fully_connected(fc3, n_units=3, activation='softmax')\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=net, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.000001).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_board(game_board, sess):\n",
    "    next_boards = game_board.find_all_next_board_positions()\n",
    "    next_inputs = [ele.get_NN_inputs() for ele in next_boards]\n",
    "    batch_board = np.array([ele[0] for ele in next_inputs])\n",
    "    batch_aux = np.array([ele[1] for ele in next_inputs])\n",
    "    evaluation = sess.run(net, feed_dict={board: batch_board, aux: batch_aux})\n",
    "    #chosen_movenum = np.argmax(evaluation, 0)[-2*(int(a.white_tomove) - 1)]\n",
    "    chosen_movenum = np.random.choice(np.argsort(evaluation[:, -2*(int(a.white_tomove) - 1)])[:2])\n",
    "    return next_boards[chosen_movenum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing games...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Training...\n",
      "Epoch: 001 Step: 000 Loss: 0.4558501\n",
      "Epoch: 001 Step: 020 Loss: 0.41615006\n",
      "Epoch: 001 Step: 040 Loss: 0.40350753\n",
      "Epoch: 001 Step: 060 Loss: 0.4137539\n",
      "Playing games...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Training...\n",
      "Epoch: 001 Step: 000 Loss: 0.35974506\n",
      "Epoch: 001 Step: 020 Loss: 0.3970214\n",
      "Epoch: 001 Step: 040 Loss: 0.38447893\n",
      "Epoch: 001 Step: 060 Loss: 0.38391757\n",
      "Playing games...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Training...\n",
      "Epoch: 001 Step: 000 Loss: 0.41203672\n",
      "Epoch: 001 Step: 020 Loss: 0.37722775\n",
      "Epoch: 001 Step: 040 Loss: 0.36757508\n",
      "Epoch: 001 Step: 060 Loss: 0.3870871\n",
      "Playing games...\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-60d4bd7a0e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#do first 30 moves for each side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mnextboard_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_NN_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-18df09a9fffd>\u001b[0m in \u001b[0;36mget_next_board\u001b[0;34m(game_board, sess)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_aux\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#chosen_movenum = np.argmax(evaluation, 0)[-2*(int(a.white_tomove) - 1)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mchosen_movenum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhite_tomove\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pschale/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for j in range(100):\n",
    "    all_games = np.empty((0,4))\n",
    "\n",
    "    print('Playing games...')\n",
    "    for gamenum in range(0, 50):\n",
    "        print(gamenum)\n",
    "        a = cg.game_board()\n",
    "        b = a.copy()\n",
    "        board_positions_ar = np.empty((0, 64, 8))\n",
    "        aux_ar = np.empty((0,7))\n",
    "        move_info = np.empty((0,2))\n",
    "        score = None\n",
    "        for i in range(60): #do first 30 moves for each side\n",
    "            a = get_next_board(a, sess)\n",
    "\n",
    "            nextboard_inputs = a.get_NN_inputs()\n",
    "            board_positions_ar = np.append(board_positions_ar, [nextboard_inputs[0]], axis=0)\n",
    "            move_info = np.append(move_info, np.array([[gamenum, i]]), axis=0)\n",
    "            aux_ar = np.append(aux_ar, [nextboard_inputs[1]], axis=0)\n",
    "            game_end = a.game_over()\n",
    "\n",
    "            if game_end[0]:\n",
    "                score = game_end[0]\n",
    "                break\n",
    "\n",
    "        if score:\n",
    "            score = int((-2)*score + 2)\n",
    "        else:\n",
    "            material = a.to_csv_format()[-2:]\n",
    "            if material[0] > material[1]:\n",
    "                score = 0\n",
    "            elif material[1] > material[0]:\n",
    "                score = 2\n",
    "            else:\n",
    "                score = 1\n",
    "\n",
    "        score_onehot = np.zeros((board_positions_ar.shape[0],3))\n",
    "        score_onehot[:,score] = move_info[:,0]/move_info[:,0].size\n",
    "\n",
    "        game_array = np.array([board_positions_ar, aux_ar, score_onehot, move_info, np.array([])])[:4]\n",
    "        xp = np.array([[game_array[0][i], game_array[1][i], game_array[2][i], game_array[3][i]] for i in range(i)])\n",
    "\n",
    "        all_games = np.append(all_games, xp, axis=0)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    for epoch in range(1):  # 1 epochs\n",
    "        for i in range(61):\n",
    "            boards_selected = all_games[np.random.choice(range(all_games.shape[0]), 100), :]\n",
    "            batch_board = np.stack(boards_selected[:, 0])\n",
    "            batch_aux = np.stack(boards_selected[:, 1])\n",
    "            batch_ys = np.stack(boards_selected[:, 2])\n",
    "            cost = sess.run(loss, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})\n",
    "            if i % 20 == 0:\n",
    "                print(\"Epoch:\", '%03d' % (epoch + 1), \"Step:\", '%03d' % i,\n",
    "                      \"Loss:\", str(cost))\n",
    "                \n",
    "            sess.run(optimizer, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cg.game_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_next_board(a, sess)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plays a game and saves the game to a numpy file\n",
    "# the format it's saved in probably isn't ideal for training\n",
    "# to avoid getting stuck in dumb loops, this randomly picks from the top 5 moves\n",
    "\n",
    "all_games = np.empty((0,4))\n",
    "\n",
    "for gamenum in range(0, 10):\n",
    "    print(gamenum)\n",
    "    a = cg.game_board()\n",
    "    b = a.copy()\n",
    "    board_positions_ar = np.empty((0, 64, 8))\n",
    "    aux_ar = np.empty((0,7))\n",
    "    move_info = np.empty((0,2))\n",
    "    score = None\n",
    "    for i in range(30): #do first 10 moves for each side\n",
    "        next_boards = a.find_all_next_board_positions()\n",
    "        next_inputs = [ele.get_NN_inputs() for ele in next_boards]\n",
    "        batch_board = np.array([ele[0] for ele in next_inputs])\n",
    "        batch_aux = np.array([ele[1] for ele in next_inputs])\n",
    "        evaluation = sess.run(net, feed_dict={board: batch_board, aux: batch_aux})\n",
    "        #chosen_movenum = np.argmax(evaluation, 0)[-2*(int(a.white_tomove) - 1)]\n",
    "        chosen_movenum = np.random.choice(np.argsort(evaluation[:, -2*(int(a.white_tomove) - 1)])[:5])\n",
    "        a = next_boards[chosen_movenum]\n",
    "\n",
    "        nextboard_inputs = a.get_NN_inputs()\n",
    "        board_positions_ar = np.append(board_positions_ar, [nextboard_inputs[0]], axis=0)\n",
    "        move_info = np.append(move_info, np.array([[gamenum, i]]), axis=0)\n",
    "        aux_ar = np.append(aux_ar, [nextboard_inputs[1]], axis=0)\n",
    "        game_end = a.game_over()\n",
    "        c = b.copy()\n",
    "        b = a.copy()\n",
    "        if game_end[0]:\n",
    "            score = game_end[0]\n",
    "            break\n",
    "\n",
    "    if score:\n",
    "        score = int((-2)*score + 2)\n",
    "    else:\n",
    "        material = a.to_csv_format()[-2:]\n",
    "        if material[0] > material[1]:\n",
    "            score = 0\n",
    "        elif material[1] > material[0]:\n",
    "            score = 2\n",
    "        else:\n",
    "            score = 1\n",
    "\n",
    "    score_onehot = np.zeros((board_positions_ar.shape[0],3))\n",
    "    score_onehot[:,score] = 1\n",
    "\n",
    "    game_array = np.array([board_positions_ar, aux_ar, score_onehot, move_info, np.array([])])[:4]\n",
    "    xp = np.array([[game_array[0][i], game_array[1][i], game_array[2][i], game_array[3][i]] for i in range(i)])\n",
    "\n",
    "    all_games = np.append(all_games, xp, axis=0)\n",
    "\n",
    "#print(a)\n",
    "\n",
    "np.save('ai_games/ai_game_3', all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.check_check('B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(ele) for ele in c.find_all_next_board_positions()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.find_all_legal_moves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting session and loading variables\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "#sess = tf.Session()\n",
    "#saver.restore(sess, \"/Users/pschale/pythonstuff/chess_ai_project/test_saved_CNN\")\n",
    "#saver.restore(sess, \"./test_saved_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = np.empty((0,4))\n",
    "all_games = np.append(all_games, xp, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):  # 2 epochs\n",
    "    for i in range(1):\n",
    "        boards_selected = all_games[np.random.choice(range(all_games.shape[0]), 100), :]\n",
    "        batch_board = np.stack(boards_selected[:, 0])\n",
    "        batch_aux = np.stack(boards_selected[:, 1])\n",
    "        batch_ys = np.stack(boards_selected[:, 2])\n",
    "        t = time.time()\n",
    "        sess.run(optimizer, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})\n",
    "        cost = sess.run(loss, feed_dict={board: batch_board, aux: batch_aux, Y: batch_ys})\n",
    "        print(time.time() - t)\n",
    "        if i % 20 == 0:\n",
    "            print(\"Epoch:\", '%03d' % (epoch + 1), \"Step:\", '%03d' % i,\n",
    "                  \"Loss:\", str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('ai_games/ai_game_1', all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
